{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkiwHgyr18yY",
    "outputId": "aa87ecc4-7fbb-45cf-fd5d-83dac97710f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting schedule\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Applications/anaconda3/lib/python3.12/site-packages (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /Applications/anaconda3/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Applications/anaconda3/lib/python3.12/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Applications/anaconda3/lib/python3.12/site-packages (from html5lib) (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwKH6crbKh6E"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pytz\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_COLUMNS_ZSE = ['Company Name', 'Opening Price', 'Closing Price', 'Total Traded Volume']\n",
    "EXPECTED_COLUMNS_VIC = ['Company Name', 'Opening Price', 'Closing Price', 'Total Traded Volume']\n",
    "\n",
    "class ScrapeLogger:\n",
    "    def __init__(self):\n",
    "        self.log = {\n",
    "            \"timestamp\": datetime.now(pytz.timezone('Africa/Harare')).isoformat(),\n",
    "            \"status\": \"success\",\n",
    "            \"sources\": {},\n",
    "            \"warnings\": [],\n",
    "            \"errors\": []\n",
    "        }\n",
    "    \n",
    "    def log_source(self, name, status, rows=0, columns=None, error=None):\n",
    "        self.log[\"sources\"][name] = {\n",
    "            \"status\": status,\n",
    "            \"rows_scraped\": rows,\n",
    "            \"columns_found\": columns or [],\n",
    "            \"error\": error\n",
    "        }\n",
    "        if status == \"failure\":\n",
    "            self.log[\"status\"] = \"partial\" if self.log[\"status\"] == \"success\" else \"failure\"\n",
    "    \n",
    "    def add_warning(self, msg):\n",
    "        self.log[\"warnings\"].append(msg)\n",
    "    \n",
    "    def add_error(self, msg):\n",
    "        self.log[\"errors\"].append(msg)\n",
    "        self.log[\"status\"] = \"failure\"\n",
    "    \n",
    "    def save(self, path=\"logs/scrape_log.json\"):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                history = json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            history = []\n",
    "        \n",
    "        history.append(self.log)\n",
    "        history = history[-90:]\n",
    "        \n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "\n",
    "def save_html_snapshot(source_name, html_content):\n",
    "    snapshot_dir = \"logs/html_snapshots\"\n",
    "    os.makedirs(snapshot_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = f\"{snapshot_dir}/{source_name}_{timestamp}.html\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    snapshots = sorted([f for f in os.listdir(snapshot_dir) if f.startswith(source_name)])\n",
    "    for old_snapshot in snapshots[:-5]:\n",
    "        os.remove(os.path.join(snapshot_dir, old_snapshot))\n",
    "\n",
    "logger = ScrapeLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "OzZsaUk5KkQD"
   },
   "outputs": [],
   "source": [
    "url = \"https://www.zse.co.zw/price-sheet/\"\n",
    "url2 = \"https://zimpricecheck.com/price-updates/official-and-black-market-exchange-rates/?srsltid=AfmBOoo-30J1RAcbr6OMk7Z-R0rUF_sH7WBp97Qt1O3C4FrP8n7cXhj_\"\n",
    "url3 = \"https://www.vfex.exchange/price-sheet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbQINTP9KtLM"
   },
   "outputs": [],
   "source": [
    "def get_todays_data_zse():\n",
    "    source_name = \"zse\"\n",
    "    response = None\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_html(StringIO(response.text))\n",
    "        except ValueError as e:\n",
    "            if \"No tables found\" in str(e):\n",
    "                logger.log_source(source_name, \"failure\", error=\"No tables found in HTML (website structure may have changed)\")\n",
    "                save_html_snapshot(source_name, response.text)\n",
    "                raise ValueError(f\"ZSE: No tables found in HTML\")\n",
    "            raise\n",
    "        \n",
    "        df = pd.DataFrame(data[0])\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.log_source(source_name, \"failure\", error=\"Table is empty\")\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "            raise ValueError(\"ZSE table is empty\")\n",
    "        \n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df = df.dropna()\n",
    "        \n",
    "        found_cols = list(df.columns)\n",
    "        missing_cols = [c for c in EXPECTED_COLUMNS_ZSE if c not in found_cols]\n",
    "        if missing_cols:\n",
    "            logger.add_warning(f\"ZSE missing columns: {missing_cols}\")\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        \n",
    "        extra_cols = [c for c in found_cols if c not in EXPECTED_COLUMNS_ZSE]\n",
    "        if extra_cols:\n",
    "            logger.add_warning(f\"ZSE new columns detected: {extra_cols}\")\n",
    "        \n",
    "        logger.log_source(source_name, \"success\", rows=len(df), columns=found_cols)\n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.log_source(source_name, \"failure\", error=\"Request timeout after 30s\")\n",
    "        raise\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "        if response:\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"Network error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def get_open_price_zse():\n",
    "    df = get_todays_data_zse()\n",
    "    open_price = df[['Company Name','Opening Price']].T\n",
    "    open_price.columns  = open_price.iloc[0]\n",
    "    open_price = open_price[1:]\n",
    "    open_price.index.name = 'Date'\n",
    "    open_price = open_price.rename(\n",
    "      index={open_price.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return open_price\n",
    "\n",
    "def get_close_price_zse():\n",
    "    df = get_todays_data_zse()\n",
    "    close_price = df[['Company Name','Closing Price']].T\n",
    "    close_price.columns  = close_price.iloc[0]\n",
    "    close_price = close_price[1:]\n",
    "    close_price.index.name = 'Date'\n",
    "    close_price = close_price.rename(\n",
    "      index={close_price.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return close_price\n",
    "\n",
    "def get_vol_traded_zse():\n",
    "    df = get_todays_data_zse()\n",
    "    vol_traded = df[['Company Name','Total Traded Volume']].T\n",
    "    vol_traded.columns  = vol_traded.iloc[0]\n",
    "    vol_traded = vol_traded[1:]\n",
    "    vol_traded.index.name = 'Date'\n",
    "    vol_traded = vol_traded.rename(\n",
    "      index={vol_traded.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return vol_traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_todays_data_vic():\n",
    "    source_name = \"vfex\"\n",
    "    response = None\n",
    "    try:\n",
    "        response = requests.get(url3, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_html(StringIO(response.text))\n",
    "        except ValueError as e:\n",
    "            if \"No tables found\" in str(e):\n",
    "                logger.log_source(source_name, \"failure\", error=\"No tables found in HTML (website structure may have changed)\")\n",
    "                save_html_snapshot(source_name, response.text)\n",
    "                raise ValueError(f\"VFEX: No tables found in HTML\")\n",
    "            raise\n",
    "        \n",
    "        df = pd.DataFrame(data[0])\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.log_source(source_name, \"failure\", error=\"Table is empty\")\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "            raise ValueError(\"VFEX table is empty\")\n",
    "        \n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df = df.dropna()\n",
    "        \n",
    "        found_cols = list(df.columns)\n",
    "        missing_cols = [c for c in EXPECTED_COLUMNS_VIC if c not in found_cols]\n",
    "        if missing_cols:\n",
    "            logger.add_warning(f\"VFEX missing columns: {missing_cols}\")\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        \n",
    "        extra_cols = [c for c in found_cols if c not in EXPECTED_COLUMNS_VIC]\n",
    "        if extra_cols:\n",
    "            logger.add_warning(f\"VFEX new columns detected: {extra_cols}\")\n",
    "        \n",
    "        logger.log_source(source_name, \"success\", rows=len(df), columns=found_cols)\n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.log_source(source_name, \"failure\", error=\"Request timeout after 30s\")\n",
    "        raise\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "        if response:\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"Network error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def get_open_price_vic():\n",
    "    df = get_todays_data_vic()\n",
    "    open_price = df[['Company Name','Opening Price']].T\n",
    "    open_price.columns  = open_price.iloc[0]\n",
    "    open_price = open_price[1:]\n",
    "    open_price.index.name = 'Date'\n",
    "    open_price = open_price.rename(\n",
    "      index={open_price.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return open_price\n",
    "\n",
    "def get_close_price_vic():\n",
    "    df = get_todays_data_vic()\n",
    "    close_price = df[['Company Name','Closing Price']].T\n",
    "    close_price.columns  = close_price.iloc[0]\n",
    "    close_price = close_price[1:]\n",
    "    close_price.index.name = 'Date'\n",
    "    close_price = close_price.rename(\n",
    "      index={close_price.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return close_price\n",
    "\n",
    "def get_vol_traded_vic():\n",
    "    df = get_todays_data_vic()\n",
    "    vol_traded = df[['Company Name','Total Traded Volume']].T\n",
    "    vol_traded.columns  = vol_traded.iloc[0]\n",
    "    vol_traded = vol_traded[1:]\n",
    "    vol_traded.index.name = 'Date'\n",
    "    vol_traded = vol_traded.rename(\n",
    "      index={vol_traded.index[0]: datetime.now(pytz.timezone('Africa/Harare'))})\n",
    "    return vol_traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vv2noyKKz_c",
    "outputId": "29d3a9fc-4e9d-4f6d-d09a-6c62e9855c15"
   },
   "outputs": [],
   "source": [
    "def get_rates():\n",
    "    source_name = \"rates\"\n",
    "    response = None\n",
    "    try:\n",
    "        response = requests.get(url2, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_html(StringIO(response.text))\n",
    "        except ValueError as e:\n",
    "            if \"No tables found\" in str(e):\n",
    "                logger.log_source(source_name, \"failure\", error=\"No tables found in HTML (website structure may have changed)\")\n",
    "                save_html_snapshot(source_name, response.text)\n",
    "                raise ValueError(f\"Rates: No tables found in HTML\")\n",
    "            raise\n",
    "        \n",
    "        df = pd.DataFrame(data[0])\n",
    "        \n",
    "        if df.empty:\n",
    "            logger.log_source(source_name, \"failure\", error=\"Table is empty\")\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "            raise ValueError(\"Rates table is empty\")\n",
    "\n",
    "        df['value'] = df['Value'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "        df = df.drop(columns=['Value'], axis=1)\n",
    "        \n",
    "        target_rates = [\n",
    "            '1 USD to ZiG',\n",
    "            '1 USD to ZiG Lowest Informal Sector Rate',\n",
    "            '1 USD to ZiG Highest Informal Sector Rate'\n",
    "        ]\n",
    "        filtered_rates = df[df['Rate'].isin(target_rates)]\n",
    "\n",
    "        try:\n",
    "            usd_rate = filtered_rates.loc[filtered_rates['Rate'] == '1 USD to ZiG', 'value'].values[0]\n",
    "        except IndexError:\n",
    "            usd_rate = pd.NA\n",
    "            logger.add_warning(\"Rates: USD rate not found\")\n",
    "\n",
    "        try:\n",
    "            lowest_rate = filtered_rates.loc[filtered_rates['Rate'] == '1 USD to ZiG Lowest Informal Sector Rate', 'value'].values[0]\n",
    "        except IndexError:\n",
    "            lowest_rate = pd.NA\n",
    "            logger.add_warning(\"Rates: Lowest informal rate not found\")\n",
    "\n",
    "        try:\n",
    "            highest_rate = filtered_rates.loc[filtered_rates['Rate'] == '1 USD to ZiG Highest Informal Sector Rate', 'value'].values[0]\n",
    "        except IndexError:\n",
    "            highest_rate = pd.NA\n",
    "            logger.add_warning(\"Rates: Highest informal rate not found\")\n",
    "\n",
    "        rates = pd.DataFrame([{\n",
    "            'Date': datetime.now(pytz.timezone('Africa/Harare')),\n",
    "            'USA DOLLAR': usd_rate,\n",
    "            'Lowest Informal Sector Rate': lowest_rate,\n",
    "            'Highest Informal Sector Rate': highest_rate\n",
    "        }])\n",
    "\n",
    "        logger.log_source(source_name, \"success\", rows=1, columns=['USA DOLLAR', 'Lowest Informal Sector Rate', 'Highest Informal Sector Rate'])\n",
    "        return rates\n",
    "        \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.log_source(source_name, \"failure\", error=\"Request timeout after 30s\")\n",
    "        raise\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"HTTP {e.response.status_code}: {e.response.reason}\")\n",
    "        if response:\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"Network error: {str(e)}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        logger.log_source(source_name, \"failure\", error=f\"Missing column: {str(e)}\")\n",
    "        if response:\n",
    "            save_html_snapshot(source_name, response.text)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # code to retrieve existing json files with Zim Stock Data for updating\n",
    "# open_json_zse = pd.read_json('/Users/teekaynium/Desktop/open_price_zse.json', orient = 'split')\n",
    "# close_json_zse = pd.read_json('/Users/teekaynium/Desktop/close_price_zse.json', orient = 'split')\n",
    "# vol_json_zse = pd.read_json('/Users/teekaynium/Desktop/vol_traded_zse.json', orient = 'split')\n",
    "# rates_json = pd.read_json('/Users/teekaynium/Desktop/rates.json', orient = 'split')\n",
    "# open_json_vic = pd.read_json('/Users/teekaynium/Desktop/open_price_vic.json', orient = 'split')\n",
    "# close_json_vic = pd.read_json('/Users/teekaynium/Desktop/close_price_vic.json', orient = 'split')\n",
    "# vol_json_vic = pd.read_json('/Users/teekaynium/Desktop/vol_traded_vic.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "bCqR_jiuQrRv",
    "outputId": "0ffb84b6-ffd2-4871-fd14-4c6aae2483f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code to retrieve existing json files with Zim Stock Data for updating\n",
    "open_json_zse = pd.read_json('archive-single-file/open_price_zse.json', orient = 'split')\n",
    "close_json_zse = pd.read_json('archive-single-file/close_price_zse.json', orient = 'split')\n",
    "vol_json_zse = pd.read_json('archive-single-file/vol_traded_zse.json', orient = 'split')\n",
    "rates_json = pd.read_json('archive-single-file/rates.json', orient = 'split')\n",
    "open_json_vic = pd.read_json('archive-single-file/open_price_vic.json', orient = 'split')\n",
    "close_json_vic = pd.read_json('archive-single-file/close_price_vic.json', orient = 'split')\n",
    "vol_json_vic = pd.read_json('archive-single-file/vol_traded_vic.json', orient = 'split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "oXB2mwx-LKmE",
    "outputId": "e25323de-b0fe-4520-9869-02dda7996c73"
   },
   "outputs": [],
   "source": "def update_data():\n    results = {\n        'open_price_zse': None,\n        'close_price_zse': None,\n        'vol_traded_zse': None,\n        'rates': None,\n        'open_price_vic': None,\n        'close_price_vic': None,\n        'vol_traded_vic': None,\n    }\n    \n    # ZSE update\n    try:\n        zse_data = get_todays_data_zse()\n        results['open_price_zse'] = pd.concat([open_json_zse, get_open_price_zse()], axis=0)\n        results['close_price_zse'] = pd.concat([close_json_zse, get_close_price_zse()], axis=0)\n        results['vol_traded_zse'] = pd.concat([vol_json_zse, get_vol_traded_zse()], axis=0)\n    except Exception as e:\n        logger.add_error(f\"ZSE update failed: {type(e).__name__}: {str(e)}\")\n\n    # Exchange rate update\n    try:\n        results['rates'] = pd.concat([rates_json, get_rates()], axis=0)\n    except Exception as e:\n        logger.add_error(f\"Rates update failed: {type(e).__name__}: {str(e)}\")\n\n    # VFEX update\n    try:\n        vic_data = get_todays_data_vic()\n        results['open_price_vic'] = pd.concat([open_json_vic, get_open_price_vic()], axis=0)\n        results['close_price_vic'] = pd.concat([close_json_vic, get_close_price_vic()], axis=0)\n        results['vol_traded_vic'] = pd.concat([vol_json_vic, get_vol_traded_vic()], axis=0)\n    except Exception as e:\n        logger.add_error(f\"VFEX update failed: {type(e).__name__}: {str(e)}\")\n    \n    return results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "wkX0GzJpMlP8",
    "outputId": "fec70af2-21c3-4946-df3e-118e28ce5983",
    "scrolled": true
   },
   "outputs": [],
   "source": "def save_data(results):\n    saved_count = 0\n    \n    if results['open_price_zse'] is not None:\n        results['open_price_zse'].to_json('archive-single-file/open_price_zse.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['close_price_zse'] is not None:\n        results['close_price_zse'].to_json('archive-single-file/close_price_zse.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['vol_traded_zse'] is not None:\n        results['vol_traded_zse'].to_json('archive-single-file/vol_traded_zse.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['rates'] is not None:\n        results['rates'].to_json('archive-single-file/rates.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['open_price_vic'] is not None:\n        results['open_price_vic'].to_json('archive-single-file/open_price_vic.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['close_price_vic'] is not None:\n        results['close_price_vic'].to_json('archive-single-file/close_price_vic.json', orient='split', date_format='iso')\n        saved_count += 1\n    if results['vol_traded_vic'] is not None:\n        results['vol_traded_vic'].to_json('archive-single-file/vol_traded_vic.json', orient='split', date_format='iso')\n        saved_count += 1\n    \n    return saved_count\n\ntry:\n    results = update_data()\n    saved = save_data(results)\n    \n    if saved == 0:\n        logger.add_error(\"No data was saved - all sources failed\")\n    elif saved < 7:\n        logger.add_warning(f\"Partial save: {saved}/7 files updated\")\nfinally:\n    logger.save()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "0g7KmjyNM5Ow",
    "outputId": "35593e15-1d55-417c-986d-518ba88c1d9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def save_data(open_price_zse: pd.DataFrame, close_price_zse: pd.DataFrame, vol_traded_zse: pd.DataFrame, rates: pd.DataFrame,\n",
    "#               open_price_vic: pd.DataFrame, close_price_vic: pd.DataFrame, vol_traded_vic: pd.DataFrame):\n",
    "#     \"\"\" function to save updated dataframes as json files\"\"\"\n",
    "#     # Save the DataFrames to JSON files with the timestamped directory\n",
    "#     # ZSE update\n",
    "#     open_price_zse.to_json('/Users/teekaynium/Desktop/open_price_zse.json', orient='split', date_format='iso')\n",
    "#     close_price_zse.to_json('/Users/teekaynium/Desktop/close_price_zse.json', orient='split', date_format='iso')\n",
    "#     vol_traded_zse.to_json('/Users/teekaynium/Desktop/vol_traded_zse.json', orient='split', date_format='iso')\n",
    "\n",
    "#     # Exchange rates update\n",
    "#     rates.to_json('/Users/teekaynium/Desktop/rates.json', orient='split', date_format='iso')\n",
    "\n",
    "#     # VFEX update\n",
    "#     open_price_vic.to_json('/Users/teekaynium/Desktop/open_price_vic.json', orient='split', date_format='iso')\n",
    "#     close_price_vic.to_json('/Users/teekaynium/Desktop/close_price_vic.json', orient='split', date_format='iso')\n",
    "#     vol_traded_vic.to_json('/Users/teekaynium/Desktop/vol_traded_vic.json', orient='split', date_format='iso')\n",
    "    \n",
    "\n",
    "# save_data(update_data()[0], update_data()[1] , update_data()[2], update_data()[3], update_data()[4] , update_data()[5], update_data()[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def save_data(rates: pd.DataFrame, open_price_vic: pd.DataFrame, close_price_vic: pd.DataFrame, vol_traded_vic: pd.DataFrame):\n",
    "#     \"\"\" function to save updated dataframes as json files\"\"\"\n",
    "#     # # Save the DataFrames to JSON files with the timestamped directory\n",
    "#     # # ZSE update\n",
    "#     # open_price_zse.to_json('/Users/teekaynium/Desktop/open_price_zse.json', orient='split', date_format='iso')\n",
    "#     # close_price_zse.to_json('/Users/teekaynium/Desktop/close_price_zse.json', orient='split', date_format='iso')\n",
    "#     # vol_traded_zse.to_json('/Users/teekaynium/Desktop/vol_traded_zse.json', orient='split', date_format='iso')\n",
    "\n",
    "#     # Exchange rates update\n",
    "#     rates.to_json('/Users/teekaynium/Desktop/rates.json', orient='split', date_format='iso')\n",
    "\n",
    "#     # VFEX update\n",
    "#     open_price_vic.to_json('/Users/teekaynium/Desktop/open_price_vic.json', orient='split', date_format='iso')\n",
    "#     close_price_vic.to_json('/Users/teekaynium/Desktop/close_price_vic.json', orient='split', date_format='iso')\n",
    "#     vol_traded_vic.to_json('/Users/teekaynium/Desktop/vol_traded_vic.json', orient='split', date_format='iso')\n",
    "    \n",
    "\n",
    "# save_data(get_rates(), get_open_price_vic(), get_open_price_vic() , get_open_price_vic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}